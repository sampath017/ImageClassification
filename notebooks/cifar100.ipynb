{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T16:18:53.484908Z",
     "iopub.status.busy": "2024-10-16T16:18:53.484604Z",
     "iopub.status.idle": "2024-10-16T16:18:58.953389Z",
     "shell.execute_reply": "2024-10-16T16:18:58.952570Z",
     "shell.execute_reply.started": "2024-10-16T16:18:53.484876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision.transforms import v2\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from trainer import Trainer\n",
    "from module import ResNetModule\n",
    "from utils import model_size, load_from_checkpoint\n",
    "from callbacks import OverfitCallback, EarlyStoppingCallback\n",
    "from logger import WandbLogger\n",
    "from dataset import MapDataset\n",
    "import settings as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T16:19:22.754626Z",
     "iopub.status.busy": "2024-10-16T16:19:22.754254Z",
     "iopub.status.idle": "2024-10-16T16:19:22.807647Z",
     "shell.execute_reply": "2024-10-16T16:19:22.806609Z",
     "shell.execute_reply.started": "2024-10-16T16:19:22.754579Z"
    },
    "id": "qrqvKqDjWyD9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_path = Path(\"../data\")\n",
    "logs_path = Path(\"../logs\")\n",
    "logs_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T16:18:59.005310Z",
     "iopub.status.busy": "2024-10-16T16:18:59.005021Z",
     "iopub.status.idle": "2024-10-16T16:19:22.752936Z",
     "shell.execute_reply": "2024-10-16T16:19:22.751992Z",
     "shell.execute_reply.started": "2024-10-16T16:18:59.005276Z"
    },
    "id": "e48Wu90cQZYP",
    "outputId": "d2d91142-1b68-465b-d802-9a5c73628a8a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "logger = WandbLogger(\n",
    "    project_name=s.project_name,\n",
    "    config={\n",
    "        \"model\": s.model,\n",
    "        \"dataset\": s.dataset,\n",
    "        \"max_epochs\": s.max_epochs,\n",
    "        \"optimizer\": s.optimizer,\n",
    "        \"lr_scheduler\": s.lr_scheduler\n",
    "    },\n",
    "    logs_path=logs_path,\n",
    "    offline=s.wandb_offline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T16:19:22.817159Z",
     "iopub.status.busy": "2024-10-16T16:19:22.816408Z",
     "iopub.status.idle": "2024-10-16T16:19:26.500427Z",
     "shell.execute_reply": "2024-10-16T16:19:26.499455Z",
     "shell.execute_reply.started": "2024-10-16T16:19:22.817113Z"
    },
    "id": "ZdeO0nyOXfTK",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# cpu_count = os.cpu_count()\n",
    "cpu_count = 7\n",
    "\n",
    "dataset = CIFAR100(data_path, train=True, download=True)\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    dataset, [s.dataset[\"train_split\"], s.dataset[\"val_split\"]]\n",
    ")\n",
    "\n",
    "normalize_transforms = v2.Compose([\n",
    "    # Normalize\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transforms_list = []\n",
    "if s.dataset[\"augumentations\"]:\n",
    "    transforms_list.extend([\n",
    "        v2.RandomCrop(size=(32, 32), padding=4, padding_mode='reflect'),\n",
    "        v2.RandomHorizontalFlip(),\n",
    "        \n",
    "        # v2.RandomCrop(size=(32, 32), padding=4, padding_mode='reflect'),  # Random cropping\n",
    "        # v2.RandomHorizontalFlip(),  # Horizontal flip\n",
    "        # v2.RandomVerticalFlip(p=0.2),  # Vertical flip with 20% probability\n",
    "        # v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color adjustments\n",
    "        # v2.RandomRotation(degrees=15),  # Random rotation within Â±15 degrees\n",
    "        # v2.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random translation\n",
    "        # v2.RandomGrayscale(p=0.1),  # Convert to grayscale with 10% probability\n",
    "    ])\n",
    "\n",
    "# Add normalization (always)\n",
    "transforms_list.append(normalize_transforms)\n",
    "\n",
    "# Compose the transforms\n",
    "train_transforms = v2.Compose(transforms_list)\n",
    "val_transforms = normalize_transforms\n",
    "\n",
    "train_dataset = MapDataset(train_dataset, transform=train_transforms)\n",
    "val_dataset = MapDataset(val_dataset, transform=val_transforms)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=s.dataset[\"batch_size\"], shuffle=True, num_workers=cpu_count, pin_memory=True)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, batch_size=s.dataset[\"batch_size\"],  num_workers=cpu_count, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStoppingCallback(min_val_accuracy=90.0, accuracy_diff=5.0, wait_epochs=5),\n",
    "    # OverfitCallback(limit_batches=1, batch_size=10, max_epochs=500, augument_data=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneCycleLR\n"
     ]
    }
   ],
   "source": [
    "module = ResNetModule(toy_model=False)\n",
    "optimizer = optim.AdamW(\n",
    "    params=module.model.parameters(),\n",
    "    weight_decay=s.optimizer[\"weight_decay\"] if s.optimizer[\"weight_decay\"] else 0.01\n",
    ")\n",
    "\n",
    "try:\n",
    "    if s.lr_scheduler[\"name\"] == \"OneCycleLR\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer=optimizer,\n",
    "            max_lr=s.lr_scheduler[\"max_lr\"],\n",
    "            epochs=s.max_epochs,\n",
    "            steps_per_epoch=len(train_dataloader),\n",
    "        )\n",
    "\n",
    "        print(s.lr_scheduler[\"name\"])\n",
    "except TypeError:\n",
    "    lr_scheduler = None\n",
    "    print(\"lr_scheduler is None!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [32, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [32, 64, 32, 32]             128\n",
      "              ReLU-3           [32, 64, 32, 32]               0\n",
      "         ConvBlock-4           [32, 64, 32, 32]               0\n",
      "            Conv2d-5          [32, 128, 32, 32]          73,728\n",
      "       BatchNorm2d-6          [32, 128, 32, 32]             256\n",
      "              ReLU-7          [32, 128, 32, 32]               0\n",
      "         ConvBlock-8          [32, 128, 32, 32]               0\n",
      "            Conv2d-9          [32, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-10          [32, 128, 32, 32]             256\n",
      "             ReLU-11          [32, 128, 32, 32]               0\n",
      "           Conv2d-12          [32, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-13          [32, 128, 32, 32]             256\n",
      "             ReLU-14          [32, 128, 32, 32]               0\n",
      "         ResBlock-15          [32, 128, 32, 32]               0\n",
      "           Conv2d-16          [32, 256, 32, 32]         294,912\n",
      "      BatchNorm2d-17          [32, 256, 32, 32]             512\n",
      "             ReLU-18          [32, 256, 32, 32]               0\n",
      "        ConvBlock-19          [32, 256, 32, 32]               0\n",
      "           Conv2d-20          [32, 512, 32, 32]       1,179,648\n",
      "      BatchNorm2d-21          [32, 512, 32, 32]           1,024\n",
      "             ReLU-22          [32, 512, 32, 32]               0\n",
      "        ConvBlock-23          [32, 512, 32, 32]               0\n",
      "           Conv2d-24          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-25          [32, 512, 32, 32]           1,024\n",
      "             ReLU-26          [32, 512, 32, 32]               0\n",
      "           Conv2d-27          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-28          [32, 512, 32, 32]           1,024\n",
      "             ReLU-29          [32, 512, 32, 32]               0\n",
      "         ResBlock-30          [32, 512, 32, 32]               0\n",
      "           Conv2d-31          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-32          [32, 512, 32, 32]           1,024\n",
      "             ReLU-33          [32, 512, 32, 32]               0\n",
      "        ConvBlock-34          [32, 512, 32, 32]               0\n",
      "           Conv2d-35          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-36          [32, 512, 32, 32]           1,024\n",
      "             ReLU-37          [32, 512, 32, 32]               0\n",
      "        ConvBlock-38          [32, 512, 32, 32]               0\n",
      "           Conv2d-39          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-40          [32, 512, 32, 32]           1,024\n",
      "             ReLU-41          [32, 512, 32, 32]               0\n",
      "           Conv2d-42          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-43          [32, 512, 32, 32]           1,024\n",
      "             ReLU-44          [32, 512, 32, 32]               0\n",
      "         ResBlock-45          [32, 512, 32, 32]               0\n",
      "           Conv2d-46          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-47          [32, 512, 32, 32]           1,024\n",
      "             ReLU-48          [32, 512, 32, 32]               0\n",
      "        ConvBlock-49          [32, 512, 32, 32]               0\n",
      "           Conv2d-50          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-51          [32, 512, 32, 32]           1,024\n",
      "             ReLU-52          [32, 512, 32, 32]               0\n",
      "        ConvBlock-53          [32, 512, 32, 32]               0\n",
      "           Conv2d-54          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-55          [32, 512, 32, 32]           1,024\n",
      "             ReLU-56          [32, 512, 32, 32]               0\n",
      "           Conv2d-57          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-58          [32, 512, 32, 32]           1,024\n",
      "             ReLU-59          [32, 512, 32, 32]               0\n",
      "         ResBlock-60          [32, 512, 32, 32]               0\n",
      "           Conv2d-61          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-62          [32, 512, 32, 32]           1,024\n",
      "             ReLU-63          [32, 512, 32, 32]               0\n",
      "        ConvBlock-64          [32, 512, 32, 32]               0\n",
      "           Conv2d-65          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-66          [32, 512, 32, 32]           1,024\n",
      "             ReLU-67          [32, 512, 32, 32]               0\n",
      "        ConvBlock-68          [32, 512, 32, 32]               0\n",
      "           Conv2d-69          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-70          [32, 512, 32, 32]           1,024\n",
      "             ReLU-71          [32, 512, 32, 32]               0\n",
      "           Conv2d-72          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-73          [32, 512, 32, 32]           1,024\n",
      "             ReLU-74          [32, 512, 32, 32]               0\n",
      "         ResBlock-75          [32, 512, 32, 32]               0\n",
      "           Conv2d-76          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-77          [32, 512, 32, 32]           1,024\n",
      "             ReLU-78          [32, 512, 32, 32]               0\n",
      "        ConvBlock-79          [32, 512, 32, 32]               0\n",
      "           Conv2d-80          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-81          [32, 512, 32, 32]           1,024\n",
      "             ReLU-82          [32, 512, 32, 32]               0\n",
      "        ConvBlock-83          [32, 512, 32, 32]               0\n",
      "           Conv2d-84          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-85          [32, 512, 32, 32]           1,024\n",
      "             ReLU-86          [32, 512, 32, 32]               0\n",
      "           Conv2d-87          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-88          [32, 512, 32, 32]           1,024\n",
      "             ReLU-89          [32, 512, 32, 32]               0\n",
      "         ResBlock-90          [32, 512, 32, 32]               0\n",
      "           Conv2d-91          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-92          [32, 512, 32, 32]           1,024\n",
      "             ReLU-93          [32, 512, 32, 32]               0\n",
      "        ConvBlock-94          [32, 512, 32, 32]               0\n",
      "           Conv2d-95          [32, 512, 32, 32]       2,359,296\n",
      "      BatchNorm2d-96          [32, 512, 32, 32]           1,024\n",
      "             ReLU-97          [32, 512, 32, 32]               0\n",
      "        ConvBlock-98          [32, 512, 32, 32]               0\n",
      "           Conv2d-99          [32, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-100          [32, 512, 32, 32]           1,024\n",
      "            ReLU-101          [32, 512, 32, 32]               0\n",
      "          Conv2d-102          [32, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-103          [32, 512, 32, 32]           1,024\n",
      "            ReLU-104          [32, 512, 32, 32]               0\n",
      "        ResBlock-105          [32, 512, 32, 32]               0\n",
      "          Conv2d-106          [32, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-107          [32, 512, 32, 32]           1,024\n",
      "            ReLU-108          [32, 512, 32, 32]               0\n",
      "       ConvBlock-109          [32, 512, 32, 32]               0\n",
      "          Conv2d-110          [32, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-111          [32, 512, 32, 32]           1,024\n",
      "            ReLU-112          [32, 512, 32, 32]               0\n",
      "       ConvBlock-113          [32, 512, 32, 32]               0\n",
      "          Conv2d-114          [32, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-115          [32, 512, 32, 32]           1,024\n",
      "            ReLU-116          [32, 512, 32, 32]               0\n",
      "          Conv2d-117          [32, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-118          [32, 512, 32, 32]           1,024\n",
      "            ReLU-119          [32, 512, 32, 32]               0\n",
      "        ResBlock-120          [32, 512, 32, 32]               0\n",
      "          Conv2d-121          [32, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-122          [32, 512, 32, 32]           1,024\n",
      "            ReLU-123          [32, 512, 32, 32]               0\n",
      "       ConvBlock-124          [32, 512, 32, 32]               0\n",
      "          Conv2d-125          [32, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-126          [32, 512, 32, 32]           1,024\n",
      "            ReLU-127          [32, 512, 32, 32]               0\n",
      "       ConvBlock-128          [32, 512, 32, 32]               0\n",
      "          Conv2d-129          [32, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-130          [32, 512, 32, 32]           1,024\n",
      "            ReLU-131          [32, 512, 32, 32]               0\n",
      "          Conv2d-132          [32, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-133          [32, 512, 32, 32]           1,024\n",
      "            ReLU-134          [32, 512, 32, 32]               0\n",
      "        ResBlock-135          [32, 512, 32, 32]               0\n",
      "          Conv2d-136          [32, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-137          [32, 512, 32, 32]           1,024\n",
      "            ReLU-138          [32, 512, 32, 32]               0\n",
      "       ConvBlock-139          [32, 512, 32, 32]               0\n",
      "          Conv2d-140          [32, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-141          [32, 512, 32, 32]           1,024\n",
      "            ReLU-142          [32, 512, 32, 32]               0\n",
      "       ConvBlock-143          [32, 512, 32, 32]               0\n",
      "          Conv2d-144          [32, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-145          [32, 512, 32, 32]           1,024\n",
      "            ReLU-146          [32, 512, 32, 32]               0\n",
      "          Conv2d-147          [32, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-148          [32, 512, 32, 32]           1,024\n",
      "            ReLU-149          [32, 512, 32, 32]               0\n",
      "        ResBlock-150          [32, 512, 32, 32]               0\n",
      "          Conv2d-151          [32, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-152          [32, 512, 32, 32]           1,024\n",
      "            ReLU-153          [32, 512, 32, 32]               0\n",
      "       ConvBlock-154          [32, 512, 32, 32]               0\n",
      "          Conv2d-155          [32, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-156          [32, 512, 32, 32]           1,024\n",
      "            ReLU-157          [32, 512, 32, 32]               0\n",
      "       ConvBlock-158          [32, 512, 32, 32]               0\n",
      "          Conv2d-159          [32, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-160          [32, 512, 32, 32]           1,024\n",
      "            ReLU-161          [32, 512, 32, 32]               0\n",
      "          Conv2d-162          [32, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-163          [32, 512, 32, 32]           1,024\n",
      "            ReLU-164          [32, 512, 32, 32]               0\n",
      "        ResBlock-165          [32, 512, 32, 32]               0\n",
      "          Conv2d-166          [32, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-167          [32, 512, 32, 32]           1,024\n",
      "            ReLU-168          [32, 512, 32, 32]               0\n",
      "       MaxPool2d-169          [32, 512, 16, 16]               0\n",
      "       ConvBlock-170          [32, 512, 16, 16]               0\n",
      "          Conv2d-171          [32, 512, 16, 16]       2,359,296\n",
      "     BatchNorm2d-172          [32, 512, 16, 16]           1,024\n",
      "            ReLU-173          [32, 512, 16, 16]               0\n",
      "       ConvBlock-174          [32, 512, 16, 16]               0\n",
      "          Conv2d-175          [32, 512, 16, 16]       2,359,296\n",
      "     BatchNorm2d-176          [32, 512, 16, 16]           1,024\n",
      "            ReLU-177          [32, 512, 16, 16]               0\n",
      "          Conv2d-178          [32, 512, 16, 16]       2,359,296\n",
      "     BatchNorm2d-179          [32, 512, 16, 16]           1,024\n",
      "            ReLU-180          [32, 512, 16, 16]               0\n",
      "        ResBlock-181          [32, 512, 16, 16]               0\n",
      "          Conv2d-182          [32, 512, 16, 16]       2,359,296\n",
      "     BatchNorm2d-183          [32, 512, 16, 16]           1,024\n",
      "            ReLU-184          [32, 512, 16, 16]               0\n",
      "       MaxPool2d-185            [32, 512, 8, 8]               0\n",
      "       ConvBlock-186            [32, 512, 8, 8]               0\n",
      "          Conv2d-187            [32, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-188            [32, 512, 8, 8]           1,024\n",
      "            ReLU-189            [32, 512, 8, 8]               0\n",
      "       ConvBlock-190            [32, 512, 8, 8]               0\n",
      "          Conv2d-191            [32, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-192            [32, 512, 8, 8]           1,024\n",
      "            ReLU-193            [32, 512, 8, 8]               0\n",
      "          Conv2d-194            [32, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-195            [32, 512, 8, 8]           1,024\n",
      "            ReLU-196            [32, 512, 8, 8]               0\n",
      "        ResBlock-197            [32, 512, 8, 8]               0\n",
      "          Conv2d-198            [32, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-199            [32, 512, 8, 8]           1,024\n",
      "            ReLU-200            [32, 512, 8, 8]               0\n",
      "       MaxPool2d-201            [32, 512, 4, 4]               0\n",
      "       ConvBlock-202            [32, 512, 4, 4]               0\n",
      "          Conv2d-203            [32, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-204            [32, 512, 4, 4]           1,024\n",
      "            ReLU-205            [32, 512, 4, 4]               0\n",
      "       ConvBlock-206            [32, 512, 4, 4]               0\n",
      "          Conv2d-207            [32, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-208            [32, 512, 4, 4]           1,024\n",
      "            ReLU-209            [32, 512, 4, 4]               0\n",
      "          Conv2d-210            [32, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-211            [32, 512, 4, 4]           1,024\n",
      "            ReLU-212            [32, 512, 4, 4]               0\n",
      "        ResBlock-213            [32, 512, 4, 4]               0\n",
      "       MaxPool2d-214            [32, 512, 1, 1]               0\n",
      "         Flatten-215                  [32, 512]               0\n",
      "          Linear-216                  [32, 256]         131,328\n",
      "          Linear-217                  [32, 100]          25,700\n",
      "================================================================\n",
      "Total params: 120,020,388\n",
      "Trainable params: 120,020,388\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.38\n",
      "Forward/backward pass size (MB): 20410.34\n",
      "Params size (MB): 457.84\n",
      "Estimated Total Size (MB): 20868.55\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# module.model, optimizer = load_from_checkpoint(\n",
    "#     path=\"../logs/wandb/offline-run-20241215_132918-77n093vj/checkpoints/best.pt\",\n",
    "#     model=module.model,\n",
    "#     optimizer=optimizer\n",
    "# )\n",
    "\n",
    "summary(module.model, input_size=(train_dataset[0][0].shape), batch_size=s.dataset[\"batch_size\"], device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T16:19:26.511478Z",
     "iopub.status.busy": "2024-10-16T16:19:26.511073Z",
     "iopub.status.idle": "2024-10-16T16:19:26.783322Z",
     "shell.execute_reply": "2024-10-16T16:19:26.782365Z",
     "shell.execute_reply.started": "2024-10-16T16:19:26.511414Z"
    },
    "id": "jJEUcS0-Xf9N",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda!\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    module=module,\n",
    "    logger=logger,\n",
    "    optimizer=optimizer,\n",
    "    callbacks=callbacks,\n",
    "    logs_path=logs_path,\n",
    "    fast_dev_run=s.fast_dev_run,\n",
    "    measure_time=True,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    save_checkpoint_type=\"best_val\",\n",
    "    num_workers=cpu_count\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T16:19:26.784997Z",
     "iopub.status.busy": "2024-10-16T16:19:26.784612Z",
     "iopub.status.idle": "2024-10-16T16:33:32.678177Z",
     "shell.execute_reply": "2024-10-16T16:33:32.677331Z",
     "shell.execute_reply.started": "2024-10-16T16:19:26.784949Z"
    },
    "id": "9SmUWgkRXkng",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../logs/wandb/run-20241220_124225-wx46bpvd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sampath017/ImageClassification/runs/wx46bpvd' target=\"_blank\">usual-rain-343</a></strong> to <a href='https://wandb.ai/sampath017/ImageClassification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sampath017/ImageClassification' target=\"_blank\">https://wandb.ai/sampath017/ImageClassification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sampath017/ImageClassification/runs/wx46bpvd' target=\"_blank\">https://wandb.ai/sampath017/ImageClassification/runs/wx46bpvd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run stopped!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>step_train_accuracy</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>step_train_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>training_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>0.0004</td></tr><tr><td>model_architecture</td><td>ResNet56(\n",
       "  (feature...</td></tr><tr><td>step_train_accuracy</td><td>3.125</td></tr><tr><td>step_train_loss</td><td>4.7302</td></tr><tr><td>training_step</td><td>80</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">usual-rain-343</strong> at: <a href='https://wandb.ai/sampath017/ImageClassification/runs/wx46bpvd' target=\"_blank\">https://wandb.ai/sampath017/ImageClassification/runs/wx46bpvd</a><br/> View project at: <a href='https://wandb.ai/sampath017/ImageClassification' target=\"_blank\">https://wandb.ai/sampath017/ImageClassification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>../logs/wandb/run-20241220_124225-wx46bpvd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    trainer.fit(train_dataloader, val_dataloader)\n",
    "except KeyboardInterrupt as e:\n",
    "    print(\"Run stopped!\")\n",
    "finally:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Metrics](https://api.wandb.ai/links/sampath017/iwrrziwg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5863031,
     "sourceId": 9608953,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
