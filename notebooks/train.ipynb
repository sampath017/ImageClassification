{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T16:18:53.484908Z",
     "iopub.status.busy": "2024-10-16T16:18:53.484604Z",
     "iopub.status.idle": "2024-10-16T16:18:58.953389Z",
     "shell.execute_reply": "2024-10-16T16:18:58.952570Z",
     "shell.execute_reply.started": "2024-10-16T16:18:53.484876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision.datasets import CIFAR10, Food101\n",
    "from torchvision.transforms import v2\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from trainer import Trainer\n",
    "from module import ResidualNetModule\n",
    "from utils import model_size\n",
    "from callbacks import OverfitCallback, EarlyStoppingCallback\n",
    "from logger import WandbLogger\n",
    "from dataset import MapDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T16:19:22.754626Z",
     "iopub.status.busy": "2024-10-16T16:19:22.754254Z",
     "iopub.status.idle": "2024-10-16T16:19:22.807647Z",
     "shell.execute_reply": "2024-10-16T16:19:22.806609Z",
     "shell.execute_reply.started": "2024-10-16T16:19:22.754579Z"
    },
    "id": "qrqvKqDjWyD9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_path = Path(\"../data\")\n",
    "logs_path = Path(\"../logs\")\n",
    "logs_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T16:18:59.005310Z",
     "iopub.status.busy": "2024-10-16T16:18:59.005021Z",
     "iopub.status.idle": "2024-10-16T16:19:22.752936Z",
     "shell.execute_reply": "2024-10-16T16:19:22.751992Z",
     "shell.execute_reply.started": "2024-10-16T16:18:59.005276Z"
    },
    "id": "e48Wu90cQZYP",
    "outputId": "d2d91142-1b68-465b-d802-9a5c73628a8a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "logger = WandbLogger(\n",
    "    project_name=\"ImageClassification\",\n",
    "    config={\n",
    "        \"model_architecture\": \"ResidualNet\",\n",
    "        \"num_model_layers\": 20,\n",
    "        \"batch_size\": 128,\n",
    "        \"max_epochs\": 200,\n",
    "        \"optimizer\": {\n",
    "            \"name\": \"Adam\",\n",
    "        },\n",
    "        \"train_split\": 0.7,\n",
    "        \"val_split\": 0.3\n",
    "    },\n",
    "    logs_path=logs_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T16:19:22.817159Z",
     "iopub.status.busy": "2024-10-16T16:19:22.816408Z",
     "iopub.status.idle": "2024-10-16T16:19:26.500427Z",
     "shell.execute_reply": "2024-10-16T16:19:26.499455Z",
     "shell.execute_reply.started": "2024-10-16T16:19:22.817113Z"
    },
    "id": "ZdeO0nyOXfTK",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cpu_count = os.cpu_count()\n",
    "dataset = CIFAR10(data_path, train=True, download=True)\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    dataset, [logger.config[\"train_split\"], logger.config[\"val_split\"]]\n",
    ")\n",
    "\n",
    "val_transforms = v2.Compose([\n",
    "    # Normalize\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = MapDataset(train_dataset, transform=v2.Compose([\n",
    "    # Data auguments\n",
    "    v2.RandomCrop(size=(32, 32), padding=4, padding_mode='reflect'),\n",
    "    v2.RandomHorizontalFlip(),\n",
    "\n",
    "    val_transforms\n",
    "]))\n",
    "\n",
    "val_dataset = MapDataset(val_dataset, transform=val_transforms)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=logger.config[\"batch_size\"], shuffle=True, num_workers=cpu_count, pin_memory=True)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, batch_size=logger.config[\"batch_size\"],  num_workers=cpu_count, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStoppingCallback(min_val_accuracy=80.0, accuracy_diff=5.0, wait_epochs=5),\n",
    "    # OverfitCallback(limit_batches=1, batch_size=10, max_epochs=500, augument_data=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T16:19:26.511478Z",
     "iopub.status.busy": "2024-10-16T16:19:26.511073Z",
     "iopub.status.idle": "2024-10-16T16:19:26.783322Z",
     "shell.execute_reply": "2024-10-16T16:19:26.782365Z",
     "shell.execute_reply.started": "2024-10-16T16:19:26.511414Z"
    },
    "id": "jJEUcS0-Xf9N",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 32, 32]             216\n",
      "       BatchNorm2d-2            [-1, 8, 32, 32]              16\n",
      "              ReLU-3            [-1, 8, 32, 32]               0\n",
      "            Conv2d-4           [-1, 16, 32, 32]           1,152\n",
      "       BatchNorm2d-5           [-1, 16, 32, 32]              32\n",
      "              ReLU-6           [-1, 16, 32, 32]               0\n",
      "         MaxPool2d-7           [-1, 16, 16, 16]               0\n",
      "         ConvBlock-8           [-1, 16, 16, 16]               0\n",
      "            Conv2d-9           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-10           [-1, 32, 16, 16]              64\n",
      "             ReLU-11           [-1, 32, 16, 16]               0\n",
      "           Conv2d-12           [-1, 64, 16, 16]          18,432\n",
      "      BatchNorm2d-13           [-1, 64, 16, 16]             128\n",
      "             ReLU-14           [-1, 64, 16, 16]               0\n",
      "        MaxPool2d-15             [-1, 64, 8, 8]               0\n",
      "        ConvBlock-16             [-1, 64, 8, 8]               0\n",
      "          Dropout-17             [-1, 64, 8, 8]               0\n",
      "           Conv2d-18            [-1, 128, 8, 8]          73,728\n",
      "      BatchNorm2d-19            [-1, 128, 8, 8]             256\n",
      "             ReLU-20            [-1, 128, 8, 8]               0\n",
      "           Conv2d-21            [-1, 512, 8, 8]         589,824\n",
      "      BatchNorm2d-22            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-23            [-1, 512, 8, 8]               0\n",
      "        MaxPool2d-24            [-1, 512, 4, 4]               0\n",
      "        ConvBlock-25            [-1, 512, 4, 4]               0\n",
      "           Conv2d-26            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-27            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-28            [-1, 512, 4, 4]               0\n",
      "           Conv2d-29            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-30            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-31            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-32            [-1, 512, 2, 2]               0\n",
      "    ResidualBlock-33            [-1, 512, 2, 2]               0\n",
      "          Dropout-34            [-1, 512, 2, 2]               0\n",
      "           Conv2d-35            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-37            [-1, 512, 2, 2]               0\n",
      "           Conv2d-38            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-40            [-1, 512, 2, 2]               0\n",
      "    ResidualBlock-41            [-1, 512, 2, 2]               0\n",
      "           Conv2d-42            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-43            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-44            [-1, 512, 2, 2]               0\n",
      "           Conv2d-45            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-46            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-47            [-1, 512, 2, 2]               0\n",
      "    ResidualBlock-48            [-1, 512, 2, 2]               0\n",
      "          Dropout-49            [-1, 512, 2, 2]               0\n",
      "           Conv2d-50            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-51            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-52            [-1, 512, 2, 2]               0\n",
      "           Conv2d-53            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-54            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-55            [-1, 512, 2, 2]               0\n",
      "    ResidualBlock-56            [-1, 512, 2, 2]               0\n",
      "           Conv2d-57            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-58            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-59            [-1, 512, 2, 2]               0\n",
      "           Conv2d-60            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-62            [-1, 512, 2, 2]               0\n",
      "    ResidualBlock-63            [-1, 512, 2, 2]               0\n",
      "          Dropout-64            [-1, 512, 2, 2]               0\n",
      "           Conv2d-65            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-66            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-67            [-1, 512, 2, 2]               0\n",
      "           Conv2d-68            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-69            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-70            [-1, 512, 2, 2]               0\n",
      "    ResidualBlock-71            [-1, 512, 2, 2]               0\n",
      "           Conv2d-72            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-73            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-74            [-1, 512, 2, 2]               0\n",
      "           Conv2d-75            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-76            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-77            [-1, 512, 2, 2]               0\n",
      "    ResidualBlock-78            [-1, 512, 2, 2]               0\n",
      "          Dropout-79            [-1, 512, 2, 2]               0\n",
      "           Conv2d-80            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-81            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-82            [-1, 512, 2, 2]               0\n",
      "           Conv2d-83            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-84            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-85            [-1, 512, 2, 2]               0\n",
      "    ResidualBlock-86            [-1, 512, 2, 2]               0\n",
      "           Conv2d-87            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-88            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-89            [-1, 512, 2, 2]               0\n",
      "           Conv2d-90            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-91            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-92            [-1, 512, 2, 2]               0\n",
      "    ResidualBlock-93            [-1, 512, 2, 2]               0\n",
      "          Dropout-94            [-1, 512, 2, 2]               0\n",
      "           Conv2d-95            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-96            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-97            [-1, 512, 2, 2]               0\n",
      "           Conv2d-98            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-99            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-100            [-1, 512, 2, 2]               0\n",
      "   ResidualBlock-101            [-1, 512, 2, 2]               0\n",
      "          Conv2d-102            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-103            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-104            [-1, 512, 2, 2]               0\n",
      "          Conv2d-105            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-106            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-107            [-1, 512, 2, 2]               0\n",
      "   ResidualBlock-108            [-1, 512, 2, 2]               0\n",
      "         Dropout-109            [-1, 512, 2, 2]               0\n",
      "          Conv2d-110            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-111            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-112            [-1, 512, 2, 2]               0\n",
      "          Conv2d-113            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-114            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-115            [-1, 512, 2, 2]               0\n",
      "   ResidualBlock-116            [-1, 512, 2, 2]               0\n",
      "          Conv2d-117            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-118            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-119            [-1, 512, 2, 2]               0\n",
      "          Conv2d-120            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-121            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-122            [-1, 512, 2, 2]               0\n",
      "   ResidualBlock-123            [-1, 512, 2, 2]               0\n",
      "         Dropout-124            [-1, 512, 2, 2]               0\n",
      "          Conv2d-125            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-126            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-127            [-1, 512, 2, 2]               0\n",
      "          Conv2d-128            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-129            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-130            [-1, 512, 2, 2]               0\n",
      "   ResidualBlock-131            [-1, 512, 2, 2]               0\n",
      "          Conv2d-132            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-133            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-134            [-1, 512, 2, 2]               0\n",
      "          Conv2d-135            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-136            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-137            [-1, 512, 2, 2]               0\n",
      "   ResidualBlock-138            [-1, 512, 2, 2]               0\n",
      "         Dropout-139            [-1, 512, 2, 2]               0\n",
      "          Conv2d-140            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-141            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-142            [-1, 512, 2, 2]               0\n",
      "          Conv2d-143            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-144            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-145            [-1, 512, 2, 2]               0\n",
      "   ResidualBlock-146            [-1, 512, 2, 2]               0\n",
      "          Conv2d-147            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-148            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-149            [-1, 512, 2, 2]               0\n",
      "          Conv2d-150            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-151            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-152            [-1, 512, 2, 2]               0\n",
      "   ResidualBlock-153            [-1, 512, 2, 2]               0\n",
      "         Dropout-154            [-1, 512, 2, 2]               0\n",
      "          Conv2d-155            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-156            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-157            [-1, 512, 2, 2]               0\n",
      "          Conv2d-158            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-159            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-160            [-1, 512, 2, 2]               0\n",
      "   ResidualBlock-161            [-1, 512, 2, 2]               0\n",
      "          Conv2d-162            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-163            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-164            [-1, 512, 2, 2]               0\n",
      "          Conv2d-165            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-166            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-167            [-1, 512, 2, 2]               0\n",
      "   ResidualBlock-168            [-1, 512, 2, 2]               0\n",
      "         Dropout-169            [-1, 512, 2, 2]               0\n",
      "          Conv2d-170            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-171            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-172            [-1, 512, 2, 2]               0\n",
      "          Conv2d-173            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-174            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-175            [-1, 512, 2, 2]               0\n",
      "   ResidualBlock-176            [-1, 512, 2, 2]               0\n",
      "          Conv2d-177            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-178            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-179            [-1, 512, 2, 2]               0\n",
      "          Conv2d-180            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-181            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-182            [-1, 512, 2, 2]               0\n",
      "   ResidualBlock-183            [-1, 512, 2, 2]               0\n",
      "         Dropout-184            [-1, 512, 2, 2]               0\n",
      "          Conv2d-185            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-186            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-187            [-1, 512, 2, 2]               0\n",
      "          Conv2d-188            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-189            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-190            [-1, 512, 2, 2]               0\n",
      "   ResidualBlock-191            [-1, 512, 2, 2]               0\n",
      "          Conv2d-192            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-193            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-194            [-1, 512, 2, 2]               0\n",
      "          Conv2d-195            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-196            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-197            [-1, 512, 2, 2]               0\n",
      "   ResidualBlock-198            [-1, 512, 2, 2]               0\n",
      "         Dropout-199            [-1, 512, 2, 2]               0\n",
      "          Conv2d-200            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-201            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-202            [-1, 512, 2, 2]               0\n",
      "          Conv2d-203            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-204            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-205            [-1, 512, 2, 2]               0\n",
      "   ResidualBlock-206            [-1, 512, 2, 2]               0\n",
      "          Conv2d-207            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-208            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-209            [-1, 512, 2, 2]               0\n",
      "          Conv2d-210            [-1, 512, 2, 2]       2,359,808\n",
      "   ResidualBlock-211            [-1, 512, 2, 2]               0\n",
      "          Linear-212                  [-1, 128]         262,272\n",
      "            ReLU-213                  [-1, 128]               0\n",
      "          Linear-214                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 118,968,530\n",
      "Trainable params: 118,968,530\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.53\n",
      "Params size (MB): 453.83\n",
      "Estimated Total Size (MB): 459.37\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "module = ResidualNetModule()\n",
    "\n",
    "trainer = Trainer(\n",
    "    module=module,\n",
    "    logger=logger,\n",
    "    callbacks=callbacks,\n",
    "    logs_path=logs_path,\n",
    "    fast_dev_run=False,\n",
    "    measure_time=True,\n",
    "    checkpoint=\"best_train\",\n",
    "    num_workers=cpu_count\n",
    ")\n",
    "\n",
    "summary(module.model, input_size=(train_dataset[0][0].shape), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T16:19:26.784997Z",
     "iopub.status.busy": "2024-10-16T16:19:26.784612Z",
     "iopub.status.idle": "2024-10-16T16:33:32.678177Z",
     "shell.execute_reply": "2024-10-16T16:33:32.677331Z",
     "shell.execute_reply.started": "2024-10-16T16:19:26.784949Z"
    },
    "id": "9SmUWgkRXkng",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msampath017\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../logs/wandb/run-20241213_182731-9fkofh7x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sampath017/ImageClassification/runs/9fkofh7x' target=\"_blank\">deft-cosmos-247</a></strong> to <a href='https://wandb.ai/sampath017/ImageClassification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sampath017/ImageClassification' target=\"_blank\">https://wandb.ai/sampath017/ImageClassification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sampath017/ImageClassification/runs/9fkofh7x' target=\"_blank\">https://wandb.ai/sampath017/ImageClassification/runs/9fkofh7x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time per epoch: 29.46 seconds\n",
      "Epoch: 0, train_accuracy: 10.40, val_accuracy: 9.96\n",
      "Epoch: 1, train_accuracy: 14.00, val_accuracy: 24.86\n",
      "Epoch: 2, train_accuracy: 27.87, val_accuracy: 37.12\n",
      "Epoch: 3, train_accuracy: 37.33, val_accuracy: 42.75\n",
      "Epoch: 4, train_accuracy: 41.91, val_accuracy: 45.49\n",
      "Epoch: 5, train_accuracy: 45.32, val_accuracy: 45.25\n",
      "Epoch: 6, train_accuracy: 49.86, val_accuracy: 55.14\n",
      "Epoch: 7, train_accuracy: 55.66, val_accuracy: 62.17\n",
      "Epoch: 8, train_accuracy: 59.49, val_accuracy: 58.68\n",
      "Epoch: 9, train_accuracy: 62.06, val_accuracy: 65.95\n",
      "Epoch: 10, train_accuracy: 63.97, val_accuracy: 66.64\n",
      "Epoch: 11, train_accuracy: 64.69, val_accuracy: 62.85\n",
      "Epoch: 12, train_accuracy: 66.88, val_accuracy: 71.22\n",
      "Epoch: 13, train_accuracy: 68.80, val_accuracy: 72.69\n",
      "Epoch: 14, train_accuracy: 70.66, val_accuracy: 74.42\n",
      "Epoch: 15, train_accuracy: 66.05, val_accuracy: 72.04\n",
      "Epoch: 16, train_accuracy: 69.11, val_accuracy: 72.35\n",
      "Epoch: 17, train_accuracy: 71.13, val_accuracy: 77.12\n",
      "Epoch: 18, train_accuracy: 71.73, val_accuracy: 77.32\n",
      "Epoch: 19, train_accuracy: 72.48, val_accuracy: 76.52\n",
      "Epoch: 20, train_accuracy: 75.53, val_accuracy: 79.21\n",
      "Epoch: 21, train_accuracy: 77.36, val_accuracy: 79.22\n",
      "Epoch: 22, train_accuracy: 78.26, val_accuracy: 77.82\n",
      "Epoch: 23, train_accuracy: 79.21, val_accuracy: 80.79\n",
      "Epoch: 24, train_accuracy: 79.89, val_accuracy: 81.06\n",
      "Epoch: 25, train_accuracy: 78.91, val_accuracy: 72.84\n",
      "Epoch: 26, train_accuracy: 77.11, val_accuracy: 81.53\n",
      "Epoch: 27, train_accuracy: 80.90, val_accuracy: 81.73\n",
      "Epoch: 28, train_accuracy: 78.96, val_accuracy: 73.55\n",
      "Epoch: 29, train_accuracy: 77.90, val_accuracy: 81.53\n",
      "Epoch: 30, train_accuracy: 81.49, val_accuracy: 82.97\n",
      "Epoch: 31, train_accuracy: 83.32, val_accuracy: 82.81\n",
      "Epoch: 32, train_accuracy: 82.79, val_accuracy: 83.23\n",
      "Epoch: 33, train_accuracy: 84.18, val_accuracy: 83.90\n",
      "Epoch: 34, train_accuracy: 82.02, val_accuracy: 82.88\n",
      "Epoch: 35, train_accuracy: 84.43, val_accuracy: 83.66\n",
      "Epoch: 36, train_accuracy: 85.31, val_accuracy: 83.56\n",
      "Epoch: 37, train_accuracy: 85.72, val_accuracy: 84.29\n",
      "Epoch: 38, train_accuracy: 86.12, val_accuracy: 85.55\n",
      "Epoch: 39, train_accuracy: 86.47, val_accuracy: 84.41\n",
      "Epoch: 40, train_accuracy: 84.26, val_accuracy: 78.37\n",
      "Epoch: 41, train_accuracy: 84.58, val_accuracy: 83.90\n",
      "Epoch: 42, train_accuracy: 86.91, val_accuracy: 85.45\n",
      "Epoch: 43, train_accuracy: 87.56, val_accuracy: 85.26\n",
      "Epoch: 44, train_accuracy: 88.07, val_accuracy: 85.73\n",
      "Epoch: 45, train_accuracy: 88.56, val_accuracy: 86.32\n",
      "Epoch: 46, train_accuracy: 88.86, val_accuracy: 84.81\n",
      "Epoch: 47, train_accuracy: 88.20, val_accuracy: 85.96\n",
      "Epoch: 48, train_accuracy: 89.35, val_accuracy: 85.90\n",
      "Epoch: 49, train_accuracy: 89.86, val_accuracy: 86.36\n",
      "Epoch: 50, train_accuracy: 89.73, val_accuracy: 84.08\n",
      "Epoch: 51, train_accuracy: 89.70, val_accuracy: 85.70\n",
      "Epoch: 52, train_accuracy: 90.37, val_accuracy: 86.30\n",
      "Epoch: 53, train_accuracy: 90.73, val_accuracy: 86.29\n",
      "Epoch: 54, train_accuracy: 91.00, val_accuracy: 86.49\n",
      "Epoch: 55, train_accuracy: 91.24, val_accuracy: 86.63\n",
      "Epoch: 56, train_accuracy: 91.67, val_accuracy: 86.15\n",
      "Epoch: 57, train_accuracy: 92.09, val_accuracy: 85.87\n",
      "Epoch: 58, train_accuracy: 92.35, val_accuracy: 86.58\n",
      "Epoch: 59, train_accuracy: 92.29, val_accuracy: 86.68\n",
      "Epoch: 60, train_accuracy: 92.47, val_accuracy: 86.95\n",
      "Epoch: 61, train_accuracy: 92.50, val_accuracy: 86.98\n",
      "Epoch: 62, train_accuracy: 92.84, val_accuracy: 87.01\n",
      "Epoch: 63, train_accuracy: 93.14, val_accuracy: 86.14\n",
      "Epoch: 64, train_accuracy: 92.97, val_accuracy: 86.64\n",
      "Epoch: 65, train_accuracy: 93.55, val_accuracy: 85.73\n",
      "Epoch: 66, train_accuracy: 93.82, val_accuracy: 86.82\n",
      "Epoch: 67, train_accuracy: 93.91, val_accuracy: 86.99\n",
      "Epoch: 68, train_accuracy: 93.96, val_accuracy: 86.46\n",
      "Epoch: 69, train_accuracy: 94.15, val_accuracy: 86.94\n",
      "Epoch: 70, train_accuracy: 94.24, val_accuracy: 86.38\n",
      "Epoch: 71, train_accuracy: 94.25, val_accuracy: 86.14\n",
      "Epoch: 72, train_accuracy: 94.59, val_accuracy: 87.19\n",
      "Epoch: 73, train_accuracy: 94.76, val_accuracy: 86.45\n",
      "Epoch: 74, train_accuracy: 94.89, val_accuracy: 86.67\n",
      "Epoch: 75, train_accuracy: 94.99, val_accuracy: 86.90\n",
      "Epoch: 76, train_accuracy: 93.67, val_accuracy: 73.72\n",
      "Epoch: 77, train_accuracy: 90.93, val_accuracy: 86.43\n",
      "Epoch: 78, train_accuracy: 94.06, val_accuracy: 85.80\n",
      "Epoch: 79, train_accuracy: 94.39, val_accuracy: 87.40\n",
      "Epoch: 80, train_accuracy: 95.54, val_accuracy: 87.62\n",
      "Epoch: 81, train_accuracy: 94.15, val_accuracy: 86.75\n",
      "Epoch: 82, train_accuracy: 95.13, val_accuracy: 86.81\n",
      "Epoch: 83, train_accuracy: 95.60, val_accuracy: 87.58\n",
      "Epoch: 84, train_accuracy: 95.81, val_accuracy: 87.68\n",
      "Epoch: 85, train_accuracy: 95.94, val_accuracy: 87.51\n",
      "Epoch: 86, train_accuracy: 96.35, val_accuracy: 86.91\n",
      "Epoch: 87, train_accuracy: 96.19, val_accuracy: 87.19\n",
      "Epoch: 88, train_accuracy: 96.04, val_accuracy: 87.10\n",
      "Epoch: 89, train_accuracy: 96.25, val_accuracy: 87.34\n",
      "Epoch: 90, train_accuracy: 96.39, val_accuracy: 86.78\n",
      "Epoch: 91, train_accuracy: 96.13, val_accuracy: 86.71\n",
      "Epoch: 92, train_accuracy: 96.37, val_accuracy: 87.27\n",
      "Epoch: 93, train_accuracy: 96.38, val_accuracy: 87.45\n",
      "Run stopped!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9310966a0fc44fd1b8176d51e35babd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.102 MB of 1361.922 MB uploaded\\r'), FloatProgress(value=0.000809053357147751, ma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>epoch_train_accuracy</td><td>▁▃▃▄▄▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>epoch_train_loss</td><td>█▆▅▅▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch_val_accuracy</td><td>▁▁▃▄▅▆▆▆▇▇▆▇▇▇▇▇▇███████████████████████</td></tr><tr><td>epoch_val_loss</td><td>█▇▅▅▃▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>step</td><td>▃▇▂▃▆▁█▃▄▅▃▂▆▃▂▄▂▄▂▅▄▄█▄█▆▆▇▃▇▂▆▄▅▇▆▇▂▇▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>93</td></tr><tr><td>epoch_train_accuracy</td><td>96.38377</td></tr><tr><td>epoch_train_loss</td><td>0.11403</td></tr><tr><td>epoch_val_accuracy</td><td>87.44924</td></tr><tr><td>epoch_val_loss</td><td>0.52587</td></tr><tr><td>model_architecture</td><td>ResidualNet(\n",
       "  (feat...</td></tr><tr><td>step</td><td>217</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deft-cosmos-247</strong> at: <a href='https://wandb.ai/sampath017/ImageClassification/runs/9fkofh7x' target=\"_blank\">https://wandb.ai/sampath017/ImageClassification/runs/9fkofh7x</a><br/> View project at: <a href='https://wandb.ai/sampath017/ImageClassification' target=\"_blank\">https://wandb.ai/sampath017/ImageClassification</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>../logs/wandb/run-20241213_182731-9fkofh7x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    trainer.fit(train_dataloader, val_dataloader)\n",
    "except KeyboardInterrupt as e:\n",
    "    print(\"Run stopped!\")\n",
    "finally:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Metrics](https://api.wandb.ai/links/sampath017/iwrrziwg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5863031,
     "sourceId": 9608953,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
