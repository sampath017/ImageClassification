{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision.transforms import v2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import wandb\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from utils import accuracy\n",
    "from utils import load_from_checkpoint\n",
    "from trainer import Trainer\n",
    "from models import ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(\"../data\")\n",
    "logs_path = Path(\"../logs\")\n",
    "logs_path.mkdir(exist_ok=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ..\\data\\cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ..\\data\\cifar-100-python.tar.gz to ..\\data\n"
     ]
    }
   ],
   "source": [
    "test_transforms = v2.Compose([\n",
    "    # Normalize\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "test_dataset = CIFAR100(data_path, train=False, transform=test_transforms, download=True)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, test_dataloader, device):\n",
    "    model.to(device)\n",
    "    step_test_losses = []\n",
    "    step_test_accuracies = []\n",
    "\n",
    "    model.eval()\n",
    "    num_batches = len(test_dataloader)\n",
    "    for index, batch in enumerate(test_dataloader, start=1):\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = accuracy(logits, y)\n",
    "\n",
    "        step_test_loss = loss.item()\n",
    "        step_test_accuracy = acc.item()\n",
    "        step_test_losses.append(step_test_loss)\n",
    "        step_test_accuracies.append(step_test_accuracy)\n",
    "\n",
    "        print(f\"Batch: {index}/{num_batches}, accuracy: {step_test_accuracy:.2f}\")\n",
    "\n",
    "    test_loss = torch.tensor(step_test_losses).mean()\n",
    "    test_accuracy = torch.tensor(step_test_accuracies).mean()\n",
    "\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Downloading large artifact run-24z2beff-best_val_acc_68.66.pt:v0, 319.00MB. 1 files... \n",
      "wandb:   1 of 1 files downloaded.  \n",
      "Done. 0:0:42.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [1024, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2         [1024, 64, 32, 32]             128\n",
      "              ReLU-3         [1024, 64, 32, 32]               0\n",
      "         ConvBlock-4         [1024, 64, 32, 32]               0\n",
      "            Conv2d-5        [1024, 128, 32, 32]          73,728\n",
      "       BatchNorm2d-6        [1024, 128, 32, 32]             256\n",
      "              ReLU-7        [1024, 128, 32, 32]               0\n",
      "         ConvBlock-8        [1024, 128, 32, 32]               0\n",
      "            Conv2d-9        [1024, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-10        [1024, 128, 32, 32]             256\n",
      "             ReLU-11        [1024, 128, 32, 32]               0\n",
      "        ConvBlock-12        [1024, 128, 32, 32]               0\n",
      "           Conv2d-13        [1024, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-14        [1024, 128, 32, 32]             256\n",
      "             ReLU-15        [1024, 128, 32, 32]               0\n",
      "        ConvBlock-16        [1024, 128, 32, 32]               0\n",
      "         ResBlock-17        [1024, 128, 32, 32]               0\n",
      "           Conv2d-18        [1024, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-19        [1024, 256, 16, 16]             512\n",
      "             ReLU-20        [1024, 256, 16, 16]               0\n",
      "        ConvBlock-21        [1024, 256, 16, 16]               0\n",
      "           Conv2d-22        [1024, 512, 16, 16]       1,179,648\n",
      "      BatchNorm2d-23        [1024, 512, 16, 16]           1,024\n",
      "             ReLU-24        [1024, 512, 16, 16]               0\n",
      "        ConvBlock-25        [1024, 512, 16, 16]               0\n",
      "           Conv2d-26        [1024, 512, 16, 16]       2,359,296\n",
      "      BatchNorm2d-27        [1024, 512, 16, 16]           1,024\n",
      "             ReLU-28        [1024, 512, 16, 16]               0\n",
      "        ConvBlock-29        [1024, 512, 16, 16]               0\n",
      "           Conv2d-30        [1024, 512, 16, 16]       2,359,296\n",
      "      BatchNorm2d-31        [1024, 512, 16, 16]           1,024\n",
      "             ReLU-32        [1024, 512, 16, 16]               0\n",
      "        ConvBlock-33        [1024, 512, 16, 16]               0\n",
      "         ResBlock-34        [1024, 512, 16, 16]               0\n",
      "           Conv2d-35          [1024, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-36          [1024, 512, 8, 8]           1,024\n",
      "             ReLU-37          [1024, 512, 8, 8]               0\n",
      "        ConvBlock-38          [1024, 512, 8, 8]               0\n",
      "           Conv2d-39          [1024, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-40          [1024, 512, 8, 8]           1,024\n",
      "             ReLU-41          [1024, 512, 8, 8]               0\n",
      "        ConvBlock-42          [1024, 512, 8, 8]               0\n",
      "           Conv2d-43          [1024, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-44          [1024, 512, 8, 8]           1,024\n",
      "             ReLU-45          [1024, 512, 8, 8]               0\n",
      "        ConvBlock-46          [1024, 512, 8, 8]               0\n",
      "           Conv2d-47          [1024, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-48          [1024, 512, 8, 8]           1,024\n",
      "             ReLU-49          [1024, 512, 8, 8]               0\n",
      "        ConvBlock-50          [1024, 512, 8, 8]               0\n",
      "         ResBlock-51          [1024, 512, 8, 8]               0\n",
      "           Conv2d-52          [1024, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-53          [1024, 512, 4, 4]           1,024\n",
      "             ReLU-54          [1024, 512, 4, 4]               0\n",
      "        ConvBlock-55          [1024, 512, 4, 4]               0\n",
      "           Conv2d-56          [1024, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-57          [1024, 512, 4, 4]           1,024\n",
      "             ReLU-58          [1024, 512, 4, 4]               0\n",
      "        ConvBlock-59          [1024, 512, 4, 4]               0\n",
      "           Conv2d-60          [1024, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-61          [1024, 512, 4, 4]           1,024\n",
      "             ReLU-62          [1024, 512, 4, 4]               0\n",
      "        ConvBlock-63          [1024, 512, 4, 4]               0\n",
      "           Conv2d-64          [1024, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-65          [1024, 512, 4, 4]           1,024\n",
      "             ReLU-66          [1024, 512, 4, 4]               0\n",
      "        ConvBlock-67          [1024, 512, 4, 4]               0\n",
      "         ResBlock-68          [1024, 512, 4, 4]               0\n",
      "           Conv2d-69          [1024, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-70          [1024, 512, 4, 4]           1,024\n",
      "             ReLU-71          [1024, 512, 4, 4]               0\n",
      "        ConvBlock-72          [1024, 512, 4, 4]               0\n",
      "AdaptiveAvgPool2d-73          [1024, 512, 1, 1]               0\n",
      "          Flatten-74                [1024, 512]               0\n",
      "           Linear-75                [1024, 100]          51,300\n",
      "================================================================\n",
      "Total params: 27,862,692\n",
      "Trainable params: 27,862,692\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 12.00\n",
      "Forward/backward pass size (MB): 36424.78\n",
      "Params size (MB): 106.29\n",
      "Estimated Total Size (MB): 36543.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "run = api.run(\"sampath017/ImageClassification/24z2beff\")\n",
    "artifact = api.artifact('sampath017/ImageClassification/run-24z2beff-best_val_acc_68.66.pt:v0', type='model')\n",
    "local_path = artifact.download(root=logs_path)\n",
    "checkpoint = torch.load(Path(local_path)/\"best_val_acc_68.66.pt\", weights_only=True, map_location=device)\n",
    "\n",
    "model = ResNet18(num_classes=100)\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "summary(model, input_size=(test_dataset[0][0].shape), batch_size=1024, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1/10, accuracy: 66.21\n",
      "Batch: 2/10, accuracy: 67.77\n",
      "Batch: 3/10, accuracy: 64.45\n",
      "Batch: 4/10, accuracy: 67.19\n",
      "Batch: 5/10, accuracy: 66.21\n",
      "Batch: 6/10, accuracy: 64.16\n",
      "Batch: 7/10, accuracy: 66.50\n",
      "Batch: 8/10, accuracy: 65.72\n",
      "Batch: 9/10, accuracy: 67.38\n",
      "Batch: 10/10, accuracy: 66.45\n",
      "\n",
      "loss=1.51, accuracy=66.21\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = test(model, test_dataloader, device)\n",
    "print(f\"\\n{loss=:.2f}, {accuracy=:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
